---
layout: post
title: "Big data"
date: 2016-01-18
comments: true
---


### MapReduce
It is a programming model to distribute the data into a cluster of multiple computers. It was originally created by Google for PageRank. The process includes the mapper function and reducer function.

The mapper converts the raw data into keys and values. For example, for a movie rating data, if we want to know how many movies by users, the mapper can convert the raw data into userid:movieid. In the same time, the mapper will group the data with the same key. 

Then the data are sent to reducer.  In the above example, if the reducer function is len(), then for each key (user), the reducer will calculate how many movies watched by each user. The reducer function will be applied to each key:value pair.

cat data | map | sort | reduce

{% highlight python %}
from mrjob.job import MRJob

class MoviesByUserCounter(MRJob):
	def mapper(self,key,line):
		(userID,movieID,rating,timestamp) = line.split('\t')
		yield userID,movieID

	def reducer(self, user, movies):
		numMovies = 0
		for movie in movies:
			numMoives = numMovies+1
		yield user, numMovies

if __name__ == '__main__':
	MoviesByUserCounter.run()
{% endhighlight %}

The mapper function just splits the input line and return userID and movieID. Each userID and movies are then passed into reducer function. THe reducer function calculate how many movies for each user.

### Hadoop
It is the platform that manages applicaions with MapReduce system. However, MapReduce is just one of the many systems supported by Hadoop. For example, the Hadoop platform also includes HDFS which is a file sharing system and YARN which is a communication system between computers. More imporantly, Hadoop system provides fault-tolerance. Simply put, Hadoop = MapReduce (Hive + Pig) + HDFS.


The Hadoop system will divide the data into multiple chunks and distribute them into different mappers. However, after mappers, the data with same key will go to the same reducer. In the previous example, this makes sure that the reducer will handle the same user.

Amazon provides MapReduce environment called Amazon Elastic MapReduce (Amazon EMR).

### Apache Hive 
It is a data warehouse based on Hadoop and allows SQL-like queries, which was developed by Facebook. With Hive, you don't need to write your own mapper and reducer function. 

### Apache Pig
Similar to Hive, but it's not SQL and has its own syntax called Pig Latin. Pig was originally developed by Yahoo.

### Apache Spark
It's similar to MapReduce but has its own feature. It has built-in libraries for maching learning (MLLib),SQL,streaming. Spark is much faster than MapReduce. Spark is written with Scala and it also supports Java, Python and R

### Hadoop Vendors
Many vendors provide Hadroop solutions such as Apache, Cludera, MapR and Hortonworks.